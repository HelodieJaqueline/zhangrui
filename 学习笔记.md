# 学习笔记、日常积累

## 计算机基础
### 网络

#### TCP/IP

### 操作系统
#### Linux
##### 常用命令


#### CPU

#### 内存

#### 磁盘

#### 线程

#### 进程

#### 死锁

### 数据结构和算法

算法题目积累: https://github.com/HelodieJaqueline/zhangrui.git

#### 数据结构

##### 数组

##### 链表

##### 队列

##### 字符串

##### 树

#### 算法

##### 排序

##### 动态规划

#### 查找

## 语言基础

### 集合框架

#### List

#### Set

#### Map

#### Queue

### 多线程并发

#### 多线程基础

##### 线程的生命周期

线程的6种状态(NEW、RUNNABLE、BLOCKED、WAITING、TIME_WAITING、TERMINATED)

* NEW：初始状态，线程被构建，但是还没有调用 start 方法RUNNABLED：运行状态，JAVA 线程把操作系中的就绪和运行两种状态统一称为“运行中”
* BLOCKED：阻塞状态，表示线程进入等待状态,也就是线程因为某种原因放弃了 CPU 使用权，阻塞也分为几种情况
  ➢ 等待阻塞：运行的线程执行 wait 方法，jvm 会把当前线程放入到等待队列
  ➢ 同步阻塞：运行的线程在获取对象的同步锁时，若该同步锁被其他线程锁占用了，那么 jvm 会把当前的线程放入到锁池中
  ➢ 其他阻塞：运行的线程执行 Thread.sleep 或者 t.join 方法，或者发出了 I/O 请求时，JVM 会把当前线程设置为阻塞状态，当 sleep 结束、join 线程终止、io 处理完毕则线程恢复
* TIME_WAITING：超时等待状态，超时以后自动返回
* TERMINATED：终止状态，表示当前线程执行完毕

##### 线程的启动

线程的启动，也就是调用start()方法去启动一个线程，当 run 方法中的代码执行完毕以后，线程的生命周期也将终止。调用 start 方法的语义是当前线程告诉 JVM，启动调用 start 方法的线程。

##### 线程的终止

线程的终止，并不是简单的调用 stop 命令去。虽然 api 仍然可以调用，但是和其他的线程控制方法如 suspend、resume 一样都是过期了的不建议使用，就拿 stop 来说，stop 方法在结束一个线程时并不会保证线程的资源正常释放，因此会导致程序可能出现一些不确定的状态。要优雅的去中断一个线程，在线程中提供了一个 interrupt方法。

##### interrupt() 方法

当其他线程通过调用当前线程的 interrupt 方法，表示向当前线程打个招呼，告诉他可以中断线程的执行了，至于什么时候中断，取决于当前线程自己。线程通过检查自身是否被中断来进行相应，可以通过isInterrupted()来判断是否被中断。这种通过标识位或者中断操作的方式能够使线程在终止时有机会去清理资源，而不是武断地将线程停止，因此这种终止线程的做法显得更加安全和优雅。

**thread.interrupt()**方法实际就是设置一个 interrupted 状态标识为 true、并且通过ParkEvent 的 unpark 方法来唤醒线程。

##### Thread.interrupted

通过 interrupt，设置了一个标识告诉线程可 以 终 止 了 ， 线 程 中 还 提 供 了 静 态 方 法Thread.interrupted()对设置中断标识的线程复位。

##### 其他的线程复位

除了通过 Thread.interrupted 方法对线程中断标识进行复位 以 外 ， 还 有 一 种 被 动 复 位 的 场 景 ， 就 是 对 抛 出InterruptedException 异 常 的 方 法 ， 在InterruptedException 抛出之前，JVM 会先把线程的中断标识位清除，然后才会抛出 InterruptedException，这个时候如果调用 isInterrupted 方法，将会返回 false。

##### 为什么 Object.wait、Thread.sleep 和 Thread.join 都 会 抛 出InterruptedException? 

这几个方法有一个共同点，都是属于**阻塞的方法**，而阻塞方法的释放会取决于一些外部的事件，但是**阻塞方法可能因为等不到外部的触发事件而导致无法终止**，**所以它允许一个线程请求自己来停止它正在做的事情**。当一个方法抛出 InterruptedException 时，它是在告诉调用者如果执行该方法的线程被中断，它会尝试停止正在做的事情并且通过抛出 InterruptedException 表示提前返回。所以，这个异常的意思是表示一个阻塞被其他线程中断了。然后，由于线程调用了 interrupt()中断方法，那么Object.wait、Thread.sleep 等被阻塞的线程被唤醒以后会通过 is_interrupted 方法判断中断标识的状态变化，如果发现中断标识为 true，则先清除中断标识，然后抛出InterruptedException

需要注意的是，InterruptedException 异常的抛出并不意味着线程必须终止，而是提醒当前线程有中断的操作发生，至于接下来怎么处理取决于线程本身，比如
1. 直接捕获异常不做任何处理
2. 将异常往外抛出
3. 停止当前线程，并打印异常信息

##### volatile  的作用

volatile 可以使得在**多处理器**环境下保证了**共享变量**的**可见性**。

那么到底什么是可见性呢？在单线程的环境下，如果向一个变量先写入一个值，然后在没有写干涉的情况下读取这个变量的值，那这个时候读取到的这个变量的值应该是之前写入的那个值。这本来是一个很正常的事情。但是在多线程环境下，读和写发生在不同的线程中的时候，可能会出现：读线程不能及时的读取到其他线程写入的最新的值。这就是所谓的可见性为了实现跨线程写入的内存可见性，必须使用到一些机制来实现。而 volatile 就是这样一种机制

##### volatile  关键字是如何保证可见性的？

在修改带有 volatile 修饰的成员变量时，会多一个 lock 指令。lock是一种控制指令，在多处理器环境下，lock 汇编指令可以基于总线锁或者缓存锁的机制来达到可见性的一个效果。

##### 从硬件层面了解可见性的本质

一台计算机中最核心的组件是 CPU、内存、以及 I/O 设备。在整个计算机的发展历程中，除了 CPU、内存以及 I/O 设备不断迭代升级来提升计算机处理性能之外，还有一个非常核心的矛盾点，就是这三者在处理速度的差异。CPU 的计算速度是非常快的，内存次之、最后是 IO 设备比如磁盘。而在绝大部分的程序中，一定会存在内存访问，有些可能还会存在 I/O 设备的访问为了提升计算性能，CPU 从单核升级到了多核甚至用到了超线程技术最大化提高 CPU 的处理性能，但是仅仅提升CPU 性能还不够，如果后面两者的处理性能没有跟上，意味着整体的计算效率取决于最慢的设备。为了平衡三者的速度差异，最大化的利用 CPU 提升性能，从硬件、操作系统、编译器等方面都做出了很多的优化:
1. CPU 增加了高速缓存
2. 操作系统增加了进程、线程。通过 CPU 的时间片切换最
大化的提升 CPU 的使用率
3. 编译器的指令优化，更合理的去利用好 CPU 的高速缓存
然后每一种优化，都会带来相应的问题，而这些问题也是
导致线程安全性问题的根源。为了了解前面提到的可见性
问题的本质，我们有必要去了解这些优化的过程.

CPU 高速缓存线程是 CPU 调度的最小单元，线程设计的目的最终仍然是更充分的利用计算机处理的效能，但是绝大部分的运算任务不能只依靠处理器“计算”就能完成，处理器还需要与内存交互，比如读取运算数据、存储运算结果，这个 I/O 操作是很难消除的。而由于计算机的存储设备与处理器的运算速度差距非常大，所以现代计算机系统都会增加一层读写速度尽可能接近处理器运算速度的高速缓存来作为内存和处理器之间的缓冲：将运算需要使用的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存同步到内存之中。**通过高速缓存的存储交互很好的解决了处理器与内存的速度矛盾，但是也为计算机系统带来了更高的复杂度**，**因为它引入了一个新的问题，缓存一致性。**

##### 什么叫缓存一致性？

首先，有了高速缓存的存在以后，每个 CPU 的处理过程是，先将计算需要用到的数据缓存在 CPU 高速缓存中，在 CPU进行计算时，直接从高速缓存中读取数据并且在计算完成之后写入到缓存中。在整个运算过程完成后，再把缓存中的数据同步到主内存。由于在多CPU种，每个线程可能会运行在不同的CPU内，并且每个线程拥有自己的高速缓存。同一份数据可能会被缓存到多个 CPU 中，如果在不同 CPU 中运行的不同线程看到同一份内存的缓存值不一样就会存在缓存不一致的问题为了解决缓存不一致的问题，在 CPU 层面做了很多事情，主要提供了两种解决办法
1. 总线锁
2. 缓存锁

##### 总线锁和缓存锁

总线锁，简单来说就是，在多 cpu 下，当其中一个处理器要对共享内存进行操作的时候，在总线上发出一个 LOCK#信号，这个信号使得其他处理器无法通过总线来访问到共享内存中的数据，总线锁定把 CPU 和内存之间的通信锁住了，这使得锁定期间，其他处理器不能操作其他内存地址的数据，所以总线锁定的开销比较大，这种机制显然是不合适的如何优化呢？最好的方法就是控制锁的保护粒度，我们只需要保证对于被多个 CPU 缓存的同一份数据是一致的就行。所以引入了缓存锁，它核心机制是基于缓存一致性协议来实现的。

##### 缓存一致性协议

为了达到数据访问的一致，需要各个处理器在访问缓存时遵循一些协议，在读写时根据协议来操作，常见的协议有MSI，MESI，MOSI 等。最常见的就是 MESI 协议。

#####  MESI

MESI 表示缓存行的四种状态，分别是
1. M(Modify) 表示共享数据只缓存在当前 CPU 缓存中，并且是被修改状态，也就是缓存的数据和主内存中的数
据不一致
2. E(Exclusive) 表示缓存的独占状态，数据只缓存在当前CPU 缓存中，并且没有被修改
3. S(Shared) 表示数据可能被多个 CPU 缓存，并且各个缓存中的数据和主内存数据一致
4. I(Invalid) 表示缓存已经失效在 MESI 协议中，每个缓存的缓存控制器不仅知道自己的读写操作，而且也监听(snoop)其它 Cache 的读写操作

对于 MESI 协议，从 CPU 读写角度来说会遵循以下原则：CPU 读请求：缓存处于 M、E、S 状态都可以被读取，I 状态 CPU 只能从主存中读取数据CPU 写请求：缓存处于 M、E 状态才可以被写。对于 S 状态的写，需要将其他 CPU 中缓存行置为无效才可写使用总线锁和缓存锁机制之后。

##### 总结可见性的本质

由于 CPU 高速缓存的出现使得 如果多个 cpu 同时缓存了相同的共享数据时，可能存在可见性问题。也就是 CPU0 修改了自己本地缓存的值对于 CPU1 不可见。不可见导致的后果是 CPU1 后续在对该数据进行写入操作时，是使用的脏数据。使得数据最终的结果不可预测。很多同学肯定希望想在代码里面去模拟一下可见性的问题，实际上，这种情况很难模拟。因为我们无法让某个线程指定某个特定 CPU，这是系统底层的算法， JVM 应该也是没法控制的。还有最重要的一点，就是你无法预测 CPU 缓存什么时候会把值传给主存，可能这个时间间隔非常短，短到你无法观察到。最后就是线程的执行的顺序问题，因为多线程你无法控制哪个线程的某句代码会在另一个线程的某句代码后面马上执行。所以我们只能基于它的原理去了解这样一个存在的客观事实了解到这里，大家应该会有一个疑问，刚刚不是说基于缓存一致性协议或者总线锁能够达到缓存一致性的要求吗？为什么还需要加 volatile 关键字？或者说为什么还会存在可见性问题呢？

##### MESI 优化带来的可见性问题

MESI 协议虽然可以实现缓存的一致性，但是也会存在一些问题。就是各个 CPU 缓存行的状态是通过消息传递来进行的。如果 CPU0 要对一个在缓存中共享的变量进行写入，首先需要发送一个失效的消息给到其他缓存了该数据的 CPU。并且要等到他们的确认回执。CPU0 在这段时间内都会处于阻塞状态。为了避免阻塞带来的资源浪费。在 cpu 中引入了 Store Bufferes。

CPU0 只需要在写入共享数据时，直接把数据写入到 storebufferes 中，同时发送 invalidate 消息，然后继续去处理其他指令。当收到其他所有CPU发送了invalidate acknowledge消息时，再将 store bufferes 中的数据数据存储至 cache line中。最后再从缓存行同步到主内存。

#### JMM

JMM 全称是 Java Memory Model. 什么是 JMM 呢？

JMM 属于语言级别的抽象内存模型，可以简单理解为**对硬件模型的抽象**，它定义了**共享内存中多线程程序读写操作的行为规范**：在虚拟机中把共享变量存储到内存以及从内存中取出共享变量的底层实现细节通过这些规则来规范对内存的读写操作从而保证指令的正确性，它解决了 CPU 多级缓存、处理器优化、指令重排序导致的内存访问问题，保证了并发场景下的可见性。

JMM 抽象模型分为主内存、工作内存；主内存是所有线程共享的，一般是实例对象、静态字段、数组对象等存储在堆内存中的变量。工作内存是每个线程独占的，线程对变量的所有操作都必须在工作内存中进行，不能直接读写主内存中的变量，线程之间的共享变量值的传递都是基于主内存来完成。

Java 内存模型底层实现可以简单的认为：通过内存屏障(memory barrier)禁止重排序，即时编译器根据具体的底层体系架构，将这些内存屏障替换成具体的 CPU 指令。对于编译器而言，内存屏障将限制它所能做的重排序优化。而对于处理器而言，内存屏障将会导致缓存的刷新操作。比如，对于 volatile，编译器将在 volatile 字段的读写操作前后各插入一些内存屏障。

##### JMM  是如何解决可见性有序性问题的

简单来说，JMM 提供了一些禁用缓存以及进制重排序的方法，来解决可见性和有序性问题。这些方法大家都很熟悉：**volatile、synchronized、final；**

##### JMM  如何解决顺序一致性问题

**重排序问题**

为了提高程序的执行性能，编译器和处理器都会对指令做重排序，其中处理器的重排序在前面已经分析过了。所谓
的重排序其实就是指执行的指令顺序。编译器的重排序指的是程序编写的指令在编译之后，指令可能会产生重排序来优化程序的执行性能。

##### HappenBefore

它的意思表示的是前一个操作的结果对于后续操作是可见的，所以它是一种表达多个线程之间对于内存的可见性。所以我们可以认为在 JMM 中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作必须要存在happens-before 关系。这两个操作可以是同一个线程，也可以是不同的线程。

**JMM  中有哪些方法建立  happens- -before规则**

程序顺序规则

1. 一个线程中的每个操作，happens-before 于该线程中的任意后续操作; 可以简单认为是 as-if-serial。 单个线程中的代码顺序不管怎么变，对于结果来说是不变的。
2. volatile 变量规则，对于 volatile 修饰的变量的写的操作，一定 happen-before 后续对于 volatile 变量的读操作；
3. 传递性规则，如果 1 happens-before 2; 3happens-before 4; 那么传递性规则表示: 1 happens-before 4;
4. start 规则，如果线程 A 执行操作 ThreadB.start(),那么线程 A 的 ThreadB.start()操作 happens-before 线程 B 中的任意操作。
5. join 规则，如果线程 A 执行操作 ThreadB.join()并成功返回，那么线程 B 中的任意操作 happens-before 于线程A 从 ThreadB.join()操作成功返回。
6. 监视器锁的规则，对一个锁的解锁，happens-before 于随后对这个锁的加锁。

#### JUC

Java.util.concurrent 是在并发编程中比较常用的工具类，里面包含很多用来在并发场景中使用的组件。比如线程池、阻塞队列、计时器、同步器、并发集合等等。

##### Lock

在 Lock 接口出现之前，Java 中的应用程序对于多线程的并发安全处理只能基于synchronized 关键字来解决。但是 synchronized 在有些场景中会存在一些短板，也就是它并不适合于所有的并发场景。但是在 Java5 以后，Lock 的出现可以解决synchronized 在某些场景中的短板，它比 synchronized 更加灵活。

Lock 本质上是一个接口，它定义了释放锁和获得锁的抽象方法，定义成接口就意味着它定义了锁的一个标准范，也同时意味着锁的不同实现。实现 Lock 接口的类有很多，以下为几个常见的锁实现:

* ReentrantLock：表示重入锁，它是唯一一个实现了 Lock 接口的类。**重入锁指的是线程在获得锁之后，再次获取该锁不需要阻塞**，而是直接关联一次计数器增加重入次数.
* ReentrantReadWriteLock：重入读写锁，它实现了 ReadWriteLock 接口，在这个类中维护了两个锁，一个是 ReadLock，一个是 WriteLock，他们都分别实现了 Lock接口。读写锁是一种适合读多写少的场景下解决线程安全问题的工具，基本原则是： **读和读不互斥、读和写互斥、写和写互斥**。也就是说涉及到影响数据变化的操作都会存在互斥。
* StampedLock： stampedLock 是 JDK8 引入的新的锁机制，可以简单认为是读写锁的一个改进版本，读写锁虽然通过分离读和写的功能使得读和读之间可以完全并发，但是读和写是有冲突的，如果大量的读线程存在，可能会引起写线程的饥饿。stampedLock 是一种乐观的读策略，使得乐观锁完全不会阻塞写线程。

##### Lock中的方法

* void lock()  如果锁可用就获得锁，如果锁不可用就阻塞直到锁释放
* void lockInterruptibly() 和lock()方法相似, 但阻塞的线程 可 中 断 ， 抛 出java.lang.InterruptedException 异常
* boolean tryLock()  非阻塞获取锁;尝试获取锁，如果成功返回 true
* boolean  tryLock(longtimeout, TimeUnit timeUnit) 带有超时时间的获取锁方法
* void unlock()  释放锁

##### ReentrantLock  重入锁

类图如下:

![](D:\图片\学习\JUC\ReentrantLock类图.png)

**重入锁**，表示支持重新进入的锁，也就是说，如果当前线程 t1 通过调用 lock 方法获取了锁之后，再次调用 lock，是不会再阻塞去获取锁的，直接增加重试次数就行了。synchronized 和 ReentrantLock 都是可重入锁。很多同学不理解为什么锁会存在重入的特性，那是因为对于同步锁的理解程度还不够，比如在下面这类的场景中，存在多个加锁的方法的相互调用，其实就是一种重入特性的场景。

**重入锁的设计目的**

先看一段代码

```java
public class ReentrantDemo {
    public synchronized void demo(){
        System.out.println("begin:demo");
        demo2();
    }
    public void demo2(){
        System.out.println("begin:demo1");
        synchronized (this){
        }
    }
    public static void main(String[] args) {
        ReentrantDemo rd=new ReentrantDemo();
        new Thread(rd::demo).start();
    }
}
```

调用 demo 方法获得了当前的对象锁，然后在这个方法中再去调用demo2，demo2 中的存在同一个实例锁，这个时候当前线程会因为无法获得demo2 的对象锁而阻塞，就会产生死锁。重入锁的设计目的是避免线程的死锁。

ReentrantLock 使用案例

```java
public class AtomicDemo {
private static int count=0;
static Lock lock=new ReentrantLock();
public static void inc(){
lock.lock();
try {
Thread.sleep(1);
} catch (InterruptedException e) {
e.printStackTrace();
}
count++;
lock.unlock();
}
public static void main(String[] args) throws
InterruptedException {
for(int i=0;i<1000;i++){
new Thread(()->{AtomicDemo.inc();}).start();;
}
Thread.sleep(3000);
System.out.println("result:"+count);
}
}
```

##### ReentrantReadWriteLock

我们以前理解的锁，基本都是排他锁，也就是这些锁在同一时刻只允许一个线程进行访问，而读写所在同一时刻可以允许多个线程访问，但是在写线程访问时，所有的读线程和其他写线程都会被阻塞。读写锁维护了一对锁，一个读锁、一个写锁;一般情况下，读写锁的性能都会比排它锁好，因为大多数场景读是多于写的。在读多于写的情况下，读写锁能够提供比排它锁更好的并发性和吞吐量.

```java
public class ReentrantReadWriteLockDemo {
    static Map<String,Object> cacheMap=new HashMap<>();
    static ReentrantReadWriteLock rwl=new
        ReentrantReadWriteLock();
    static Lock read=rwl.readLock();
    static Lock write=rwl.writeLock();
    public static final Object get(String key) {
        System.out.println(" 开始读取数据");
        read.lock(); // 读锁
        try {
            return cacheMap.get(key);
        }finally {
            read.unlock();
        }
    }
    public static final Object put(String key,Object value){
        write.lock();
        System.out.println(" 开始写数据");
        try{
            return cacheMap.put(key,value);
        }finally {
            write.unlock();
        }
    }
}
```

在这个案例中，通过 hashmap 来模拟了一个内存缓存，然后使用读写所来保证这个内存缓存的线程安全性。当执行读操作的时候，需要获取读锁，在并发访问的时候，读锁不会被阻塞，因为读操作不会影响执行结果。在执行写操作是，线程必须要获取写锁，当已经有线程持有写锁的情况下，当前线程会被阻塞，只有当写锁释放以后，其他读写操作才能继续执行。使用读写锁提升读操作的并发性，也保证每次写操作对所有的读写操作的可见性。

* 读锁与读锁可以共享
* 读锁与写锁不可以共享（排他）
* 写锁与写锁不可以共享（排他）

#### AQS原理

在 Lock 中，用到了一个同步队列 AQS，全称 AbstractQueuedSynchronizer，它是一个同步工具也是 Lock 用来实现线程同步的核心组件。

从使用层面来说，AQS 的功能分为两种：**独占和共享**

* 独占锁，每次只能有一个线程持有锁，比如前面给大家演示的 ReentrantLock 就是以独占方式实现的互斥锁
* 共享锁，允许多个线程同时获取锁 ，并发访问共享资源，比 如ReentrantReadWriteLock

##### AQS 内部实现原理

AQS 队列内部维护的是一个 **FIFO 的双向链表**，这种结构的特点是**每个数据结构都有两个指针**，分别指向**直接的后继节点**和**直接前驱节点**。所以双向链表可以从**任意一个节点**开始很方便的**访问前驱和后继**。**每个Node**其实是**由线程封装**，当线程**争抢锁失败**后会**封装成 Node 加入到 ASQ 队列中去**；**当获取锁的线程释放锁以后，会从队列中唤醒一个阻塞的节点(线程)。**

##### 释放锁以及添加线程对于队列的变化

当出现锁竞争以及释放锁的时候，AQS 同步队列中的节点会发生变化，首先看一下添加节点的场景。

![](C:\Users\Administrator\IdeaProjects\zhangrui\picture\juc\AQS添加新节点.png)

这里会涉及到两个变化

1. 新的线程封装成 Node 节点追加到同步队列中，设置 prev 节点以及修改当前节点的前置节点的 next 节点指向自己
2. 通过 CAS 讲 tail 重新指向新的尾部节点

head 节点表示获取锁成功的节点，当头结点在释放同步状态时，会唤醒后继节点，如果后继节点获得锁成功，会把自己设置为头结点，节点的变化过程如下:

![](C:\Users\Administrator\IdeaProjects\zhangrui\picture\juc\唤醒并设置头结点.png)

这个过程也是涉及到两个变化
1. 修改 head 节点指向下一个获得锁的节点
2. 新的获得锁的节点，将 prev 的指针指向 null

**设置 head 节点不需要用 CAS，原因是设置 head 节点是由获得锁的线程来完成的，而同步锁只能由一个线程获得，所以不需要 CAS 保证，只需要把 head 节点设置为原首节点的后继节点，并且断开原 head 节点的 next 引用即可**

##### ReentrantLock 的源码分析

ReentrantLock 时序图



#### 多线程并发工具类

#### ConcurrentHashMap原理

#### 阻塞队列及原子操作

#### 线程池原理

### JVM

JVM架构图
https://github.com/HelodieJaqueline/zhangrui/blob/master/JVM%E6%9E%B6%E6%9E%84%E5%9B%BE.png



#### 运行时数据区域

##### 程序计数器

* 程序计数器是一块较小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。字节码解释器工作时通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等功能都需要依赖这个计数器来完成。
* 为了线程切换后能**恢复到正确的执行位置**，**每条线程**都需要有一个**独立**的程序计数器，各线程之间计数器互不影响，独立存储，我们称这类内存区域为“**线程私有**”的内存。
* 程序计数器是**唯一一个不会出现 OutOfMemoryError 的内存区域**，它的生命周期随着线程的创建而创建，随着线程的结束而死亡。

##### Java虚拟机栈

*  与程序计数器一样，Java 虚拟机栈也是**线程私有**的，它的生命周期和线程相同，描述的是 Java 方法执行的内存模型，每次方法调用的数据都是通过栈传递的。

* **Java 内存可以粗糙的区分为堆内存（Heap）和栈内存 (Stack),其中栈就是现在说的虚拟机栈，或者说是虚拟机栈中局部变量表部分。** （实际上，Java 虚拟机栈是由一个个栈帧组成，而每个栈帧中都拥有：局部变量表、操作数栈、动态链接、方法出口信息。）

* **局部变量表主要存放了编译器可知的各种数据类型**（boolean、byte、char、short、int、float、long、double）、**对象引用**（reference 类型，它不同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）。

  **Java 虚拟机栈会出现两种异常：StackOverFlowError 和 OutOfMemoryError。**

  1. **tackOverFlowError：** 若 Java 虚拟机栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候，就抛出 StackOverFlowError 异常。
  2. **OutOfMemoryError：** 若 Java 虚拟机栈的内存大小允许动态扩展，且当线程请求栈时内存用完了，无法再动态扩展了，此时抛出 OutOfMemoryError 异常。

##### 本地方法栈

* 和虚拟机栈所发挥的作用非常相似，区别是： **虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。** 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。
* 本地方法被执行的时候，在本地方法栈也会创建一个栈帧，用于存放该本地方法的局部变量表、操作数栈、动态链接、出口信息。
* 方法执行完毕后相应的栈帧也会出栈并释放内存空间，也会出现 StackOverFlowError 和 OutOfMemoryError 两种异常。

##### 虚拟机栈中的各个部分

- 局部变量表：存放方法参数和方法内部定义的局部变量，以变量槽Slot为基本单位，一个Slot可以存放32位以内的数据类型，可重用。
- 操作数栈：先入后出，32位数据类型所占栈容量为1，64为数据类型所占栈容量为2
- 动态链接：常量池中符号引用有一部分在每次运行期间转换为直接引用，这部分称为动态链接。（一部分在类加载阶段或第一次使用时转换为直接引用—静态解析）
- 方法返回地址：方法执行后退出的两种方式：正常完成出口（执行引擎遇到任意一个返回的字节码指令）和异常完成出口（在方法执行过程中遇到异常且此异常未被处理）。两种方式都需要返回到方法被调用的位置程序才能继续执行（正常退出时调用者的PC计数器的值可以作为返回地址且栈帧中很可能保存这个计数器值；异常退出返回地址要通过异常处理器表来确定，栈帧中一般不会保存）。

##### Java堆

* Java 虚拟机所管理的内存中最大的一块，Java 堆是所有线程共享的一块内存区域，在虚拟机启动时创建。**此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。**
* Java 堆是垃圾收集器管理的主要区域，因此也被称作**GC 堆（Garbage Collected Heap）**.从垃圾回收的角度，由于现在收集器基本都采用分代垃圾收集算法，所以 Java 堆还可以细分为：新生代和老年代：再细致一点有：Eden 空间、From Survivor、To Survivor 空间等。**进一步划分的目的是更好地回收内存，或者更快地分配内存。**

##### 方法区

* 方法区与 Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然 Java 虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做 **Non-Heap（非堆）**，目的应该是与 Java 堆区分开来。

* **方法区和永久代的关系**:《Java 虚拟机规范》只是规定了有方法区这么个概念和它的作用，并没有规定如何去实现它。那么，在不同的 JVM 上方法区的实现肯定是不同的了。 方法区和永久代的关系很像 Java 中接口和类的关系，类实现了接口，而永久代就是 HotSpot 虚拟机对虚拟机规范中方法区的一种实现方式。 也就是说，永久代是 HotSpot 的概念，方法区是 Java 虚拟机规范中的定义，是一种规范，而永久代是一种实现，一个是标准一个是实现，其他的虚拟机实现并没有永久代这一说法。

* 相对而言，垃圾收集行为在这个区域是比较少出现的，但并非数据进入方法区后就“永久存在”了。

  JDK 1.8 的时候，方法区（HotSpot 的永久代）被彻底移除了（JDK1.7 就已经开始了），取而代之是元空间，元空间使用的是直接内存。

**为什么要将永久代 (PermGen) 替换为元空间 (MetaSpace) 呢?**

整个永久代有一个 JVM 本身设置固定大小上限，无法进行调整，而元空间使用的是直接内存，受本机可用内存的限制，并且永远不会得到 java.lang.OutOfMemoryError。你可以使用 `-XX：MaxMetaspaceSize` 标志设置最大元空间大小，默认值为 unlimited，这意味着它只受系统内存的限制。`-XX：MetaspaceSize` 调整标志定义元空间的初始大小如果未指定此标志，则 Metaspace 将根据运行时的应用程序需求动态地重新调整大小。

##### 运行时常量池

* 运行时常量池是方法区的一部分。Class 文件中除了有类的版本、字段、方法、接口等描述信息外，还有常量池信息（用于存放编译期生成的各种字面量和符号引用）

* 既然运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出 OutOfMemoryError 异常。
* DK1.7 及之后版本的 JVM 已经将运行时常量池从方法区中移了出来，在 Java 堆（Heap）中开辟了一块区域存放运行时常量池。

##### 直接内存

**直接内存并不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用。而且也可能导致 OutOfMemoryError 异常出现。**

* JDK1.4 中新加入的 **NIO(New Input/Output) 类**，引入了一种基于**通道（Channel）** 与**缓存区（Buffer）** 的 I/O 方式，它可以直接使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样就能在一些场景中显著提高性能，因为**避免了在 Java 堆和 Native 堆之间来回复制数据**。
* 本机直接内存的分配不会受到 Java 堆的限制，但是，既然是内存就会受到本机总内存大小以及处理器寻址空间的限制。

**Java中的引用**

- 强引用：new这类引用，只要强引用在，对象永远不会被回收。
- 软引用：描述有用但非必需的对象，在内存溢出之前，会把这些对象列入回收范围内进行第二次垃圾回收。
- 弱引用：描述非必需对象，只存活到下一次垃圾回收前。
- 虚引用：不会对生存时间造成影响，不能通过虚引用获得对象实例，只是在被虚引用的对象被回收时受到一个系统通知。

#### 常用参数

* 堆内存设置

#### GC

##### GC类型

##### GC算法

##### Minor GC和Full GC

- Minor GC：从新生代回收内存，关键是Eden区内存不足，造成不足的原因是Java对象大部分是朝生夕死(java局部对象)，而死掉的对象就需要在合适的时机被JVM回收
- Major GC：从老年代回收内存，一般比Minor GC慢10倍以上。
- Full GC：对整个堆来说的，出现Full GC通常伴随至少一次Minor GC，但非绝对。Full GC被触发的时候：老年代内存不足；持久代内存不足；统计得到的Minor GC晋升到老年代平均大小大于老年代空间。

##### Java虚拟机new一个对象的创建过程

- 在常量池中查看是否有new的参数对应的类的符号引用，并检查这个符号引用对应的类是否被加载、解析、初始化
- 加载后，为新对象分配内存空间，对象多需要的内存大小在类被加载之后就被确定（堆内分配内存：指针碰撞、空闲列表）。
- 将分配的空间初始化为零值。
- 对对象头进行必要设置（实例是哪个类的实例、类的元信息数据、GC分代年龄等）。
- 执行方法，按照程序的值初始化。



##### 垃圾收集器

#### 类加载

类加载过程主要包含加载、验证、准备、解析、初始化、使用、卸载七个方面

**一、加载**

在加载阶段，虚拟机主要完成三件事：

- 通过一个类的全限定名来获取定义此类的二进制字节流。
- 将这个字节流所代表的静态存储结构转化为方法区域的运行时数据结构。
- 在Java堆中生成一个代表这个类的java.lang.Class对象，作为方法区域数据的访问入口

**二、验证**

　　验证阶段作用是保证Class文件的字节流包含的信息符合JVM规范，不会给JVM造成危害。如果验证失败，就会抛出一个java.lang.VerifyError异常或其子类异常。验证过程分为四个阶段

　　1.文件格式验证：验证字节流文件是否符合Class文件格式的规范，并且能被当前虚拟机正确的处理。

　　2.元数据验证：是对字节码描述的信息进行语义分析，以保证其描述的信息符合Java语言的规范。

　　3.字节码验证：主要是进行数据流和控制流的分析，保证被校验类的方法在运行时不会危害虚拟机。

　　4.符号引用验证：符号引用验证发生在虚拟机将符号引用转化为直接引用的时候，这个转化动作将在解析阶段中发生。

**三、准备**

　　准备阶段为变量分配内存并设置类变量的初始化。在这个阶段分配的仅为类的变量(static修饰的变量)，而不包括类的实例变量。对已非final的变量，JVM会将其设置成“零值”，而不是其赋值语句的值：

　　pirvate static int size = 12;

　　那么在这个阶段，size的值为0，而不是12。 final修饰的类变量将会赋值成真实的值。

**四、解析**

　　解析过程是将常量池内的符号引用替换成直接引用。主要包括四种类型引用的解析。类或接口的解析、字段解析、方法解析、接口方法解析。

**五、初始化**

　　在准备阶段，类变量已经经过一次初始化了，在这个阶段，则是根据程序员通过程序制定的计划去初始化类的变量和其他资源。这些资源有static{}块，构造函数，父类的初始化等。

##### 类加载器

* 启动类加载器：负责加载**JRE**的核心类库，如**jre**目标下的**rt**.jar,**charsets**.jar等

* 扩展类加载器：负责加载**JRE**扩展目录**ext**中**JAR**类包

* 系统类加载器：负责加载**ClassPath**路径下的类包

* 用户自定义加载器：负责加载用户自定义路径下的类包

##### 双亲委派模型

如果一个类加载器收到类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器完成。 每个类加载器都是如此，只有当父加载器在自己的搜索范围内找不到指定的类时（即ClassNotFoundException），子加载器才会尝试自己去加载。

**为什么需要双亲委派模型？**

在这里，先想一下，如果没有双亲委派，那么用户是不是可以 自己定义一个java.lang.Object的同名类 ， java.lang.String的同名类 ，并把它放到ClassPath中,那么 类之间的比较结果及类的唯一性将无法保证 ，因此，为什么需要双亲委派模型？ 防止内存中出现多份同样的字节码

**怎么打破双亲委派模型？**

打破双亲委派机制则不仅 要继承ClassLoader 类，还要 重写loadClass和findClass 方法。



#### 调优

##### Linux命令排查

- 使用**top**命令查看系统资源占用高的进程

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND                                                                                             
   4457 root      20   0 2458m 138m  13m S 98.5  7.4   0:33.72 java                                                                                                 
    1 root      20   0 19232  952  768 S  0.0  0.0   0:07.02 init     

- 使用 top -Hp 4457 命令

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND                                                                                             
   4520 root      20   0 2458m 141m  13m R 99.2  7.5   4:40.70 java                                                                                                 
   4457 root      20   0 2458m 141m  13m S  0.0  7.5   0:00.00 java  

  - 将线程id 4520转化为16进制:11a8

- 

##### Arthas

<https://github.com/alibaba/arthas>

##### Jprofile

#### JVM常见问题

##### 为什么要分为Eden和Survivor?为什么要设置两个Survivor区？
* 如果没有Survivor，Eden区每进行一次Minor GC，存活的对象就会被送到老年代。 老年代很快被填满，触发Major GC.老年代的内存空间远大于新生代，进行一次Full GC消耗的时间比Minor GC长得多,所以需要分为Eden和Survivor。
  Survivor的存在意义，就是减少被送到老年代的对象，进而减少Full GC的发生，Survivor的预筛选保证，只有经历16次Minor GC还能在新生代中存活的对象，才会被送到老年代。
* 设置两个Survivor区最大的好处就是解决了碎片化，刚刚新建的对象在Eden中，经历一次Minor GC，Eden中的存活对象就会被移动到第一块survivor space S0，Eden被清空； 等Eden区再满了，就再触发一次Minor GC，Eden和S0中的存活对象又会被复制送入第二块survivor space S1。如果只有一块Survivor,之前存放存活对象的那块再下一次Minor GC的时候也有对象需要清除，只能用标记清除了，那么就带来内存碎片化的问题了。（这个过程非常重要，因为这种复制算法保证了S1中来自S0和Eden两部分的存活对象占用连续的内存空间，避免了碎片化的发生）

##### JVM中一次完整的GC流程是怎样的，对象如何晋升到老年代

当 Eden 区的空间满了， Java虚拟机会触发一次 Minor GC，以收集新生代的垃圾，存活下来的对象，则会转移到 Survivor区。

大对象（需要大量连续内存空间的Java对象，如那种很长的字符串） 直接进入老年态 

如果对象在Eden出生，并经过第一次Minor GC后仍然存活，并且被Survivor容纳的话，年龄设为1，每熬过一次Minor GC，年龄+1， 若年龄超过一定限制（15），则被晋升到老年态 。即 长期存活的对象进入老年态 。
动态对象年龄:如果Survivor空间中相同年龄所有对象大小之和大于Suvivor空间的一半，年龄大于前者年龄的对象会直接进入老年代。

老年代满了而 无法容纳更多的对象 ，Minor GC 之后通常就会进行Full GC，Full GC 清理整个堆内存– 包括年轻代和年老代 。

Major GC 发生在老年代的GC ， 清理老年区 ，经常会伴随至少一次Minor GC， 比Minor GC慢10倍以上 。

##### 你知道哪几种垃圾收集器，各自的优缺点，重点讲下cms和G1，包括原理，流程，优缺点。

几种垃圾收集器：

| 名称              | 简介                                                         |
| ----------------- | ------------------------------------------------------------ |
| Serial            | 单线程的收集器，收集垃圾时，必须stop the world，使用复制算法。 |
| ParNew            | Serial收集器的多线程版本，也需要stop the world，复制算法。   |
| Parallel Scavenge | 新生代收集器，复制算法的收集器，并发的多线程收集器，目标是达到一个可控的吞吐量。 如果虚拟机总共运行100分钟，其中垃圾花掉1分钟，吞吐量就是99%。 |
| Serial Old        | 是Serial收集器的老年代版本，单线程收集器，使用标记整理算法。 |
| Parallel Old      | 是Parallel Scavenge收集器的老年代版本，使用多线程，标记-整理算法。 |
| CMS               | 是一种以获得最短回收停顿时间为目标的收集器， 标记清除算法，运作过程：初始标记，并发标记，重新标记，并发清除 ，收集结束会产生大量空间碎片。 |
| G1                | 标记整理算法实现， 运作流程主要包括以下：初始标记，并发标记，最终标记，筛选标记 。 不会产生空间碎片，可以精确地控制停顿。 |



##### CMS收集器和G1收集器的区别

CMS收集器是老年代的收集器，可以配合新生代的Serial和ParNew收集器一起使用。G1收集器收集范围是老年代和新生代，不需要结合其他收集器使用；
CMS收集器以最小的停顿时间为目标的收集器。G1收集器可预测垃圾回收的停顿时间;
CMS收集器是使用“标记-清除”算法进行的垃圾回收，容易产生内存碎片。G1收集器使用的是“标记-整理”算法，进行了空间整合，降低了内存空间碎片。

##### 简单说说你了解的类加载器，可以打破双亲委派么，怎么打破。

**类加载器**:类加载器就是根据指定全限定名称将class文件加载到JVM内存，转为Class对象。

**启动类加载器**（Bootstrap ClassLoader）： 由C++语言实现（针对HotSpot）,负责将存放在lib目录或-Xbootclasspath参数指定的路径中的类库加载到内存中。
**其他类加载器**： 由Java语言实现，继承自抽象类ClassLoader。 如：
**扩展类加载器**（Extension ClassLoader）： 负责加载libext目录或java.ext.dirs系统变量指定的路径中的所有类库。
**应用程序类加载器**（Application ClassLoader）。 负责加载用户类路径（classpath）上的指定类库，我们可以直接使用这个类加载器。 一般情况，如果我们没有自定义类加载器默认就是用这个加载器。

##### 垃圾回收对象时程序的逻辑是否可以继续执行

不同回收器不同：Serial、ParNew会暂停用户所有线程工作；CMS、G1会在某一阶段暂停用户线程。

##### 内存分配策略

- 对象优先在Eden分配：若Eden无空间，Java虚拟机发起一次Minor GC。
- 大对象直接进入老年代：大对象指需要大量连续内存空间的对象（如长数组、长字符串）
- 长期存活的对象进入老年代：每个对象有一个对象年龄计数器，age=15晋升为老年代。age+1的两个情况：对象在Eden出生并经过一次Minor GC存活且被survivor容纳；在survivor区经历过一次minor GC。

##### 空间分配担保

- 在Minor GC之前，先检查老年代最大可用连续空间是否大于新生代所有空间总和，成立则此次GC安全
- 不成立，查看是否允许担保失败设置为true，不允许则进行Full GC
- 允许，看老年代最大可用连续空间是否大于历次晋升到老年代对象的平均大小，不成立则Full GC
- 成立，则进行Minor GC

##### java中方法区存放哪些东西？jvm如何控制方法区的大小以及内存溢出的原因和解决

方法区大小不是固定的，jvm可根据需要动态调整。方法区主要存放类信息、常量、静态变量、编译后的代码。

控制方法区大小：减少程序中class数量、尽量使用较少的静态变量，减少动态代理等操作

修改：-XX:MaxPerSize调大(1.8以后是元数据区，和直接内存有关)

StackOverflowError异常：线程的方法嵌套调用层次太多，随着Java栈中桢的增多，最终会由于该线程Java栈中所有栈帧总和大于-Xss设置的值而产生此异常。

##### 可以作为GC Root的对象：

1. 虚拟机栈中引用的对象
2. 方法区中类静态属性引用的对象
3. 方法区中常量引用的对象
4. 本地方法栈中Native方法引用的对象

### 设计模式

#### 单例模式

#### 工厂模式

#### 代理模式

#### 模板模式

#### 策略模式

## 数据库

### Mysql

#### 基础SQL语句

#### SQL调优

#### 存储引擎

#### 事务隔离级别

#### 锁机制

#### 读写分离

#### 分库分表

### Redis

#### Redis数据结构

#### Redis内部原理

##### LRU实现算法

#### 分布式Redis

##### Sentinel

* RAFT选举算法

##### Redis分片

* Redis代理
  * Twemproxy
  * Codis

##### Redis-Cluster

**去中心化**，只需要连接其中一个节点即可(**smart client**)

**使用CRC16算法得到Hash值后对16384取模，找到Key对于的槽位，然后找到对应的RedisGroup实例**

**扩容时槽位和RedisGroup的关系如何对应？**

使用rehash

##### 高可用

和Sentinel类似，Redis-Cluster自带主从和高可用功能

在不属于自己管理槽位的实例上操作时，需要带命令-c做Redirect,不然会报错。或者将槽位和RedisGroup对应的关系做映射并缓存起来。



#### Redis使用场景

##### 分布式缓存

##### 分布式锁

#### 一致性hash算法

Hash环顺时针查找槽位(Node)

新增和删除节点可以动态添加，但是会造成数据分布不均。可以通过引入虚拟节点解决

而Redis的槽位是固定的，不需要一致性Hash算法，使用CRC16算法得到Hash值后对16384取模

### MongoDB

#### 使用场景
* 日志记录
* 快递应用、空间(位置)查找
* 游戏场景，使用 MongoDB 存储游戏用户信息，用户的装备、积分等直接以内嵌文档的形式存储，方便查询、更新
* 物流场景，使用 MongoDB 存储订单信息，订单状态在运送过程中会不断更新，以 MongoDB 内嵌数组的形式来存储，一次查询就能将订单所有的变更读取出来。
* 社交场景，使用 MongoDB 存储存储用户信息，以及用户发表的朋友圈信息，通过地理位置索引实现附近的人、地点等功能
* 物联网场景，使用 MongoDB 存储所有接入的智能设备信息，以及设备汇报的日志信息，并对这些信息进行多维度的分析
* 视频直播，使用 MongoDB 存储用户信息、礼物信息等

#### 分片

#### 副本集

## 框架源码

### Spring

#### IOC

#### DI

#### AOP

#### MVC

#### 事务
##### 事务的基本原理
Spring 事务的本质其实就是数据库对事务的支持，没有数据库的事务支持，Spring 是无
法提供事务功能的。对于纯 JDBC 操作数据库，想要用到事务，可以按照以下步骤进行:

1. 获取连接 Connection con = DriverManager.getConnection()
2. 开启事务 con.setAutoCommit(true/false);
3. 执行 CRUD;
4. 提交事务/回滚事务 con.commit() / con.rollback();
5. 关闭连接 conn.close();

使用Spring的事务管理功能后，我们可以不再写步骤 2 和 4 的代码，而是由Spirng 自
动完成。  那么 Spring 是如何在我们书写的 CRUD 之前和之后开启事务和关闭事务的
呢？解决这个问题，也就可以从整体上理解 Spring 的事务管理实现原理了。下面简单地
介绍下，注解方式为例子
配置文件开启注解驱动，在相关的类和方法上通过注解@Transactional 标识。
Spring 在启动的时候会去解析生成相关的 bean，这时候会查看拥有相关注解的类和方
法，并且为这些类和方法生成代理，并根据@Transaction 的相关参数进行相关配置注入，
这样就在代理中为我们把相关的事务处理掉了（开启正常提交事务，异常回滚事务）。
真正的数据库层的事务提交和回滚是通过 binlog 或者 redo log 实现的。

##### Spring 事务的传播属性

所谓 spring 事务的传播属性，就是定义在存在多个事务同时存在的时候，spring 应该如
何处理这些事务的行为。这些属性在 TransactionDefinition 中定义，具体常量的解释见
下表：

| 常量名称                  | 常量解释                                                     |
| ------------------------- | ------------------------------------------------------------ |
| PROPAGATION_REQUIRED      | 支持当前事务，如果当前没有事务，就新建一个事务。这是最常见的选择，也是 Spring默认的事务的传播。 |
| PROPAGATION_REQUIRES_NEW  | 新建事务，如果当前存在事务，把当前事务挂起。新建的事务将和被挂起的事务没有任何关系，是两个独立的事务，外层事务失败回滚之后，不能回滚内层事务执行的结果，内层事务失败抛出异常，外层事务捕获，也可以不处理回滚操作 |
| PROPAGATION_SUPPORTS      | 支持当前事务，如果当前没有事务，就以非事务方式执行。         |
| PROPAGATION_MANDATORY     | 支持当前事务，如果当前没有事务，就抛出异常。                 |
| PROPAGATION_NOT_SUPPORTED | 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。   |
| PROPAGATION_NEVER         | 以非事务方式执行，如果当前存在事务，则抛出异常。             |
| PROPAGATION_NESTED        | 如果一个活动的事务存在，则运行在一个嵌套的事务中。如果没有活动事务，则按REQUIRED 属性执行。它使用了一个单独的事务，这个事务拥有多个可以回滚的保存点。内部事务的回滚不会对外部事务造成影响。它只对DataSourceTransactionManager 事务管理器起效。 |

##### 数据库隔离级别

| 隔离级别         | 隔离级别的值 | 导致的问题 |
| ---------------- | ------------ | ---------- |
| Read-Uncommitted | 0            | 脏读       |
| Read-Committed   | 1            | 避免脏读，存在不可重复读和幻读           |
| Repeatable-Read  | 2             | 避免脏读和不可重复读，存在幻读 |
|                  |              |            |



#### ORM

### SpringMVC

#### 配置阶段流程

#### 运行阶段流程

### MyBatis

#### 原理

#### 插件

### SpringBoot

#### 优点

#### 相应注解

## 分布式

### 高并发

### 消息队列

### 缓存

### 分布式事务

### 分布式锁

#### 分库分表

## 微服务

### 服务拆分

### 服务治理

#### RPC

### 注册中心

### 降级

### 限流

### 熔断



## 其他

### 中台



